{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESIÓN LINEAL MÚLTIPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Juan Javier Miño Arboleda\n",
    "29 de mayo, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condiciones que la data no debe tener para poder hacer regresión lineal múltiple\n",
    "\n",
    "![alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos métodos escogen las variables que mejor permiten modelar (averiguan las mejores variables para el modelo):\n",
    "\n",
    "![alt text](image-2.png)\n",
    "\n",
    "Eliminación Bidireccional es la mejor y la que más se aplica en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar librerias\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar el set de datos\n",
    "\n",
    "dataset = pd.read_csv('50_Startups.csv') # Importar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generación de variables\n",
    "\n",
    "x   = dataset.iloc[:, :-1].values  # Variables independientes\n",
    "y   = dataset.iloc[:, 4].values # Variable dependiente  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convertir las variables tipo Dummy: var categórica (strings) -> números -> variable Dummy\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "## Transformar el string en número\n",
    "labelencoder_X = preprocessing.LabelEncoder()  \n",
    "x[:,3] = labelencoder_X.fit_transform(x[:,3])\n",
    "\n",
    "## Transformar de número a dummy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "## El número 3 es la columna que es variable categórica\n",
    "onehotencoder = ColumnTransformer([('one_hot_encoder', OneHotEncoder(categories='auto'), [3])], remainder='passthrough')\n",
    "\n",
    "x = np.array(onehotencoder.fit_transform(x),dtype=float)\n",
    "\n",
    "## Es mejor quitar una de las columnas que se generaron de la data dummy\n",
    "x = x[:,1:] ## Antes de los : es inicio, después es fin, primero filas y luego columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dividir el dataset en entrenamiento y testing\n",
    "\n",
    "# Importar la función train_test_split desde la librería sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# x_train, x_test: contienen las variables independientes para entrenamiento y prueba, respectivamente\n",
    "# y_train, y_test: contienen las variables dependientes para entrenamiento y prueba, respectivamente\n",
    "# test_size = 0.2: En la vida real se usa el 20% para testing\n",
    "# random_state = 0: fija la semilla para el generador de números aleatorios, asegurando la reproducibilidad\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 96778.92  96479.51 105733.54  96712.8  124266.9  155752.6  132602.65\n",
      "  64926.08  35673.41 101004.64 129917.04  99937.59  97427.84 126992.93\n",
      "  71498.49 118474.03  69758.98 152211.77 134307.35 107404.34 156991.12\n",
      " 125370.37  78239.91  14681.4  191792.06 141585.52  89949.14 108552.04\n",
      " 156122.51 108733.99  90708.19 111313.02 122776.86 149759.96  81005.76\n",
      "  49490.75 182901.99 192261.83  42559.73  65200.33]\n",
      "[103015.20159797 132582.27760815 132447.73845175  71976.09851258\n",
      " 178537.48221054 116161.24230164  67851.69209676  98791.73374688\n",
      " 113969.43533012 167921.0656955 ]\n"
     ]
    }
   ],
   "source": [
    "## Regresión lineal y predicción\n",
    "\n",
    "# Importar la clase LinearRegression de sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Crear una instancia del modelo de regresión lineal\n",
    "regression = LinearRegression()\n",
    "\n",
    "# Ajustar el modelo de regresión lineal con los datos de entrenamiento\n",
    "# x_train: conjunto de datos de las variables independientes para entrenamiento\n",
    "# y_train: conjunto de datos de la variable dependiente correspondiente para entrenamiento\n",
    "regression.fit(x_train, y_train)\n",
    "\n",
    "# Utilizar el modelo entrenado para hacer predicciones sobre el conjunto de datos de prueba\n",
    "# x_test: conjunto de datos de las variables independientes para prueba\n",
    "# y_pred: contiene las predicciones de la variable dependiente basadas en x_test\n",
    "y_pred = regression.predict(x_test)\n",
    "\n",
    "print(y_train)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
